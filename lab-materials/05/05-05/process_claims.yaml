apiVersion: tekton.dev/v1beta1
kind: PipelineRun
metadata:
  name: process-claims
  annotations:
    tekton.dev/output_artifacts: '{"run-a-file": [{"key": "artifacts/$PIPELINERUN/run-a-file/mlpipeline-metrics.tgz",
      "name": "mlpipeline-metrics", "path": "/tmp/mlpipeline-metrics.json"}, {"key":
      "artifacts/$PIPELINERUN/run-a-file/mlpipeline-ui-metadata.tgz", "name": "mlpipeline-ui-metadata",
      "path": "/tmp/mlpipeline-ui-metadata.json"}], "run-a-file-2": [{"key": "artifacts/$PIPELINERUN/run-a-file-2/mlpipeline-metrics.tgz",
      "name": "mlpipeline-metrics", "path": "/tmp/mlpipeline-metrics.json"}, {"key":
      "artifacts/$PIPELINERUN/run-a-file-2/mlpipeline-ui-metadata.tgz", "name": "mlpipeline-ui-metadata",
      "path": "/tmp/mlpipeline-ui-metadata.json"}], "run-a-file-3": [{"key": "artifacts/$PIPELINERUN/run-a-file-3/mlpipeline-metrics.tgz",
      "name": "mlpipeline-metrics", "path": "/tmp/mlpipeline-metrics.json"}, {"key":
      "artifacts/$PIPELINERUN/run-a-file-3/mlpipeline-ui-metadata.tgz", "name": "mlpipeline-ui-metadata",
      "path": "/tmp/mlpipeline-ui-metadata.json"}], "run-a-file-4": [{"key": "artifacts/$PIPELINERUN/run-a-file-4/mlpipeline-metrics.tgz",
      "name": "mlpipeline-metrics", "path": "/tmp/mlpipeline-metrics.json"}, {"key":
      "artifacts/$PIPELINERUN/run-a-file-4/mlpipeline-ui-metadata.tgz", "name": "mlpipeline-ui-metadata",
      "path": "/tmp/mlpipeline-ui-metadata.json"}], "run-a-file-5": [{"key": "artifacts/$PIPELINERUN/run-a-file-5/mlpipeline-metrics.tgz",
      "name": "mlpipeline-metrics", "path": "/tmp/mlpipeline-metrics.json"}, {"key":
      "artifacts/$PIPELINERUN/run-a-file-5/mlpipeline-ui-metadata.tgz", "name": "mlpipeline-ui-metadata",
      "path": "/tmp/mlpipeline-ui-metadata.json"}], "run-a-file-6": [{"key": "artifacts/$PIPELINERUN/run-a-file-6/mlpipeline-metrics.tgz",
      "name": "mlpipeline-metrics", "path": "/tmp/mlpipeline-metrics.json"}, {"key":
      "artifacts/$PIPELINERUN/run-a-file-6/mlpipeline-ui-metadata.tgz", "name": "mlpipeline-ui-metadata",
      "path": "/tmp/mlpipeline-ui-metadata.json"}]}'
    tekton.dev/input_artifacts: '{}'
    tekton.dev/artifact_bucket: mlpipeline
    tekton.dev/artifact_endpoint: minio-service.kubeflow:9000
    tekton.dev/artifact_endpoint_scheme: http://
    tekton.dev/artifact_items: '{"run-a-file": [["mlpipeline-metrics", "/tmp/mlpipeline-metrics.json"],
      ["mlpipeline-ui-metadata", "/tmp/mlpipeline-ui-metadata.json"]], "run-a-file-2":
      [["mlpipeline-metrics", "/tmp/mlpipeline-metrics.json"], ["mlpipeline-ui-metadata",
      "/tmp/mlpipeline-ui-metadata.json"]], "run-a-file-3": [["mlpipeline-metrics",
      "/tmp/mlpipeline-metrics.json"], ["mlpipeline-ui-metadata", "/tmp/mlpipeline-ui-metadata.json"]],
      "run-a-file-4": [["mlpipeline-metrics", "/tmp/mlpipeline-metrics.json"], ["mlpipeline-ui-metadata",
      "/tmp/mlpipeline-ui-metadata.json"]], "run-a-file-5": [["mlpipeline-metrics",
      "/tmp/mlpipeline-metrics.json"], ["mlpipeline-ui-metadata", "/tmp/mlpipeline-ui-metadata.json"]],
      "run-a-file-6": [["mlpipeline-metrics", "/tmp/mlpipeline-metrics.json"], ["mlpipeline-ui-metadata",
      "/tmp/mlpipeline-ui-metadata.json"]]}'
    sidecar.istio.io/inject: "false"
    tekton.dev/template: ''
    pipelines.kubeflow.org/big_data_passing_format: $(workspaces.$TASK_NAME.path)/artifacts/$ORIG_PR_NAME/$TASKRUN_NAME/$TASK_PARAM_NAME
    pipelines.kubeflow.org/pipeline_spec: '{"inputs": [{"default": "0", "name": "claim_id",
      "optional": true, "type": "Integer"}, {"default": "https://your-endpoint", "name":
      "detection_endpoint", "optional": true, "type": "String"}], "name": "process_claims"}'
  labels:
    pipelines.kubeflow.org/pipelinename: ''
    pipelines.kubeflow.org/generation: ''
spec:
  params:
  - name: claim_id
    value: '0'
  - name: detection_endpoint
    value: https://your-endpoint
  pipelineSpec:
    params:
    - name: claim_id
      default: '0'
    - name: detection_endpoint
      default: https://your-endpoint
    tasks:
    - name: run-a-file
      params:
      - name: claim_id
        value: $(params.claim_id)
      taskSpec:
        steps:
        - name: main
          args:
          - |
            claim_id="$0"
            sh -c "mkdir -p ./jupyter-work-dir && cd ./jupyter-work-dir"
            sh -c "echo 'Downloading file:///opt/app-root/bin/utils/bootstrapper.py' && curl --fail -H 'Cache-Control: no-cache' -L file:///opt/app-root/bin/utils/bootstrapper.py --output bootstrapper.py"
            sh -c "echo 'Downloading file:///opt/app-root/bin/utils/requirements-elyra.txt' && curl --fail -H 'Cache-Control: no-cache' -L file:///opt/app-root/bin/utils/requirements-elyra.txt --output requirements-elyra.txt"
            sh -c "python3 -m pip install  packaging && python3 -m pip freeze > requirements-current.txt && python3 bootstrapper.py --pipeline-name 'process_claims' --cos-endpoint 'https://minio-api-robert-serving-test.apps.rhods-internal.61tk.p1.openshiftapps.com' --cos-bucket 'pipeline-bucket' --cos-directory 'process_claims-0111164720' --cos-dependencies-archive 'get_claims-5a1b2fe1-12c3-4c02-a958-706d09245133.tar.gz' --file 'insurance-claim-processing/lab-materials/05/05-05/get_claims.py' --outputs 'claims.json' --pipeline-parameters 'claim_id=$claim_id' --parameter-pass-method 'env' "
          - $(inputs.params.claim_id)
          command:
          - sh
          - -c
          env:
          - name: AWS_ACCESS_KEY_ID
            valueFrom:
              secretKeyRef:
                key: AWS_ACCESS_KEY_ID
                name: aws-connection-minio-pipeline
          - name: AWS_SECRET_ACCESS_KEY
            valueFrom:
              secretKeyRef:
                key: AWS_SECRET_ACCESS_KEY
                name: aws-connection-minio-pipeline
          - name: ELYRA_RUNTIME_ENV
            value: kfp
          - name: ELYRA_ENABLE_PIPELINE_INFO
            value: "True"
          - name: ELYRA_WRITABLE_CONTAINER_DIR
            value: /tmp
          - name: ELYRA_RUN_NAME
            valueFrom:
              fieldRef:
                fieldPath: metadata.annotations['pipelines.kubeflow.org/run_name']
          image: quay.io/rh-aiservices-bu/rhoai-lab-insurance-claim-processing-pipeline:1.0
        params:
        - name: claim_id
        stepTemplate:
          volumeMounts:
          - name: mlpipeline-metrics
            mountPath: /tmp
        volumes:
        - name: mlpipeline-metrics
          emptyDir: {}
        metadata:
          labels:
            elyra/node-type: notebook-script
            elyra/pipeline-name: process_claims
            elyra/pipeline-version: ''
            elyra/experiment-name: ''
            elyra/node-name: get_claims
            pipelines.kubeflow.org/cache_enabled: "true"
          annotations:
            elyra/node-file-name: insurance-claim-processing/lab-materials/05/05-05/get_claims.py
            elyra/pipeline-source: process_claims.pipeline
            pipelines.kubeflow.org/task_display_name: get_claims
            pipelines.kubeflow.org/component_spec_digest: '{"name": "Run a file",
              "outputs": [], "version": "Run a file@sha256=da5be1a681b2f0167894a310d3a8a1731b03daa22c4746f73fc71667df8f21b4"}'
    - name: run-a-file-2
      taskSpec:
        steps:
        - name: main
          args:
          - |
            sh -c "mkdir -p ./jupyter-work-dir && cd ./jupyter-work-dir"
            sh -c "echo 'Downloading file:///opt/app-root/bin/utils/bootstrapper.py' && curl --fail -H 'Cache-Control: no-cache' -L file:///opt/app-root/bin/utils/bootstrapper.py --output bootstrapper.py"
            sh -c "echo 'Downloading file:///opt/app-root/bin/utils/requirements-elyra.txt' && curl --fail -H 'Cache-Control: no-cache' -L file:///opt/app-root/bin/utils/requirements-elyra.txt --output requirements-elyra.txt"
            sh -c "python3 -m pip install  packaging && python3 -m pip freeze > requirements-current.txt && python3 bootstrapper.py --pipeline-name 'process_claims' --cos-endpoint 'https://minio-api-robert-serving-test.apps.rhods-internal.61tk.p1.openshiftapps.com' --cos-bucket 'pipeline-bucket' --cos-directory 'process_claims-0111164720' --cos-dependencies-archive 'get_accident_time-e5233ced-99d5-4420-a56b-c3244f268d46.tar.gz' --file 'insurance-claim-processing/lab-materials/05/05-05/get_accident_time.py' --inputs 'claims.json' "
          command:
          - sh
          - -c
          env:
          - name: AWS_ACCESS_KEY_ID
            valueFrom:
              secretKeyRef:
                key: AWS_ACCESS_KEY_ID
                name: aws-connection-minio-pipeline
          - name: AWS_SECRET_ACCESS_KEY
            valueFrom:
              secretKeyRef:
                key: AWS_SECRET_ACCESS_KEY
                name: aws-connection-minio-pipeline
          - name: ELYRA_RUNTIME_ENV
            value: kfp
          - name: ELYRA_ENABLE_PIPELINE_INFO
            value: "True"
          - name: ELYRA_WRITABLE_CONTAINER_DIR
            value: /tmp
          - name: ELYRA_RUN_NAME
            valueFrom:
              fieldRef:
                fieldPath: metadata.annotations['pipelines.kubeflow.org/run_name']
          image: quay.io/rh-aiservices-bu/rhoai-lab-insurance-claim-processing-pipeline:1.0
        stepTemplate:
          volumeMounts:
          - name: mlpipeline-metrics
            mountPath: /tmp
        volumes:
        - name: mlpipeline-metrics
          emptyDir: {}
        metadata:
          labels:
            elyra/node-type: notebook-script
            elyra/pipeline-name: process_claims
            elyra/pipeline-version: ''
            elyra/experiment-name: ''
            elyra/node-name: get_accident_time
            pipelines.kubeflow.org/cache_enabled: "true"
          annotations:
            elyra/node-file-name: insurance-claim-processing/lab-materials/05/05-05/get_accident_time.py
            elyra/pipeline-source: process_claims.pipeline
            pipelines.kubeflow.org/task_display_name: get_accident_time
            pipelines.kubeflow.org/component_spec_digest: '{"name": "Run a file",
              "outputs": [], "version": "Run a file@sha256=58abd6a6c89a1939bec4c701e1048c7b049b905a9a14824d59a2deeffa12450f"}'
      runAfter:
      - run-a-file
    - name: run-a-file-3
      taskSpec:
        steps:
        - name: main
          args:
          - |
            sh -c "mkdir -p ./jupyter-work-dir && cd ./jupyter-work-dir"
            sh -c "echo 'Downloading file:///opt/app-root/bin/utils/bootstrapper.py' && curl --fail -H 'Cache-Control: no-cache' -L file:///opt/app-root/bin/utils/bootstrapper.py --output bootstrapper.py"
            sh -c "echo 'Downloading file:///opt/app-root/bin/utils/requirements-elyra.txt' && curl --fail -H 'Cache-Control: no-cache' -L file:///opt/app-root/bin/utils/requirements-elyra.txt --output requirements-elyra.txt"
            sh -c "python3 -m pip install  packaging && python3 -m pip freeze > requirements-current.txt && python3 bootstrapper.py --pipeline-name 'process_claims' --cos-endpoint 'https://minio-api-robert-serving-test.apps.rhods-internal.61tk.p1.openshiftapps.com' --cos-bucket 'pipeline-bucket' --cos-directory 'process_claims-0111164720' --cos-dependencies-archive 'get_location-555e8b99-1b42-41c3-bd84-1d26889a72c9.tar.gz' --file 'insurance-claim-processing/lab-materials/05/05-05/get_location.py' --inputs 'claims.json' "
          command:
          - sh
          - -c
          env:
          - name: AWS_ACCESS_KEY_ID
            valueFrom:
              secretKeyRef:
                key: AWS_ACCESS_KEY_ID
                name: aws-connection-minio-pipeline
          - name: AWS_SECRET_ACCESS_KEY
            valueFrom:
              secretKeyRef:
                key: AWS_SECRET_ACCESS_KEY
                name: aws-connection-minio-pipeline
          - name: ELYRA_RUNTIME_ENV
            value: kfp
          - name: ELYRA_ENABLE_PIPELINE_INFO
            value: "True"
          - name: ELYRA_WRITABLE_CONTAINER_DIR
            value: /tmp
          - name: ELYRA_RUN_NAME
            valueFrom:
              fieldRef:
                fieldPath: metadata.annotations['pipelines.kubeflow.org/run_name']
          image: quay.io/rh-aiservices-bu/rhoai-lab-insurance-claim-processing-pipeline:1.0
        stepTemplate:
          volumeMounts:
          - name: mlpipeline-metrics
            mountPath: /tmp
        volumes:
        - name: mlpipeline-metrics
          emptyDir: {}
        metadata:
          labels:
            elyra/node-type: notebook-script
            elyra/pipeline-name: process_claims
            elyra/pipeline-version: ''
            elyra/experiment-name: ''
            elyra/node-name: get_location
            pipelines.kubeflow.org/cache_enabled: "true"
          annotations:
            elyra/node-file-name: insurance-claim-processing/lab-materials/05/05-05/get_location.py
            elyra/pipeline-source: process_claims.pipeline
            pipelines.kubeflow.org/task_display_name: get_location
            pipelines.kubeflow.org/component_spec_digest: '{"name": "Run a file",
              "outputs": [], "version": "Run a file@sha256=528dc0e8235ed361548a5eb37a2233b20c029786ea23acbf68a814d20dfdaf24"}'
      runAfter:
      - run-a-file
    - name: run-a-file-4
      taskSpec:
        steps:
        - name: main
          args:
          - |
            sh -c "mkdir -p ./jupyter-work-dir && cd ./jupyter-work-dir"
            sh -c "echo 'Downloading file:///opt/app-root/bin/utils/bootstrapper.py' && curl --fail -H 'Cache-Control: no-cache' -L file:///opt/app-root/bin/utils/bootstrapper.py --output bootstrapper.py"
            sh -c "echo 'Downloading file:///opt/app-root/bin/utils/requirements-elyra.txt' && curl --fail -H 'Cache-Control: no-cache' -L file:///opt/app-root/bin/utils/requirements-elyra.txt --output requirements-elyra.txt"
            sh -c "python3 -m pip install  packaging && python3 -m pip freeze > requirements-current.txt && python3 bootstrapper.py --pipeline-name 'process_claims' --cos-endpoint 'https://minio-api-robert-serving-test.apps.rhods-internal.61tk.p1.openshiftapps.com' --cos-bucket 'pipeline-bucket' --cos-directory 'process_claims-0111164720' --cos-dependencies-archive 'get_sentiment-81e80566-39c6-4f9b-a427-92bcbc7d5c92.tar.gz' --file 'insurance-claim-processing/lab-materials/05/05-05/get_sentiment.py' --inputs 'claims.json' "
          command:
          - sh
          - -c
          env:
          - name: AWS_ACCESS_KEY_ID
            valueFrom:
              secretKeyRef:
                key: AWS_ACCESS_KEY_ID
                name: aws-connection-minio-pipeline
          - name: AWS_SECRET_ACCESS_KEY
            valueFrom:
              secretKeyRef:
                key: AWS_SECRET_ACCESS_KEY
                name: aws-connection-minio-pipeline
          - name: ELYRA_RUNTIME_ENV
            value: kfp
          - name: ELYRA_ENABLE_PIPELINE_INFO
            value: "True"
          - name: ELYRA_WRITABLE_CONTAINER_DIR
            value: /tmp
          - name: ELYRA_RUN_NAME
            valueFrom:
              fieldRef:
                fieldPath: metadata.annotations['pipelines.kubeflow.org/run_name']
          image: quay.io/rh-aiservices-bu/rhoai-lab-insurance-claim-processing-pipeline:1.0
        stepTemplate:
          volumeMounts:
          - name: mlpipeline-metrics
            mountPath: /tmp
        volumes:
        - name: mlpipeline-metrics
          emptyDir: {}
        metadata:
          labels:
            elyra/node-type: notebook-script
            elyra/pipeline-name: process_claims
            elyra/pipeline-version: ''
            elyra/experiment-name: ''
            elyra/node-name: get_sentiment
            pipelines.kubeflow.org/cache_enabled: "true"
          annotations:
            elyra/node-file-name: insurance-claim-processing/lab-materials/05/05-05/get_sentiment.py
            elyra/pipeline-source: process_claims.pipeline
            pipelines.kubeflow.org/task_display_name: get_sentiment
            pipelines.kubeflow.org/component_spec_digest: '{"name": "Run a file",
              "outputs": [], "version": "Run a file@sha256=d1969409acb82d196a631affa0765081db2d582d2032693657409b6870dd46d8"}'
      runAfter:
      - run-a-file
    - name: run-a-file-5
      params:
      - name: detection_endpoint
        value: $(params.detection_endpoint)
      taskSpec:
        steps:
        - name: main
          args:
          - |
            detection_endpoint="$0"
            sh -c "mkdir -p ./jupyter-work-dir && cd ./jupyter-work-dir"
            sh -c "echo 'Downloading file:///opt/app-root/bin/utils/bootstrapper.py' && curl --fail -H 'Cache-Control: no-cache' -L file:///opt/app-root/bin/utils/bootstrapper.py --output bootstrapper.py"
            sh -c "echo 'Downloading file:///opt/app-root/bin/utils/requirements-elyra.txt' && curl --fail -H 'Cache-Control: no-cache' -L file:///opt/app-root/bin/utils/requirements-elyra.txt --output requirements-elyra.txt"
            sh -c "python3 -m pip install  packaging && python3 -m pip freeze > requirements-current.txt && python3 bootstrapper.py --pipeline-name 'process_claims' --cos-endpoint 'https://minio-api-robert-serving-test.apps.rhods-internal.61tk.p1.openshiftapps.com' --cos-bucket 'pipeline-bucket' --cos-directory 'process_claims-0111164720' --cos-dependencies-archive 'detect_objects-2b07dca0-af2c-4973-8cab-328bb18cecbf.tar.gz' --file 'insurance-claim-processing/lab-materials/05/05-05/detect_objects.py' --inputs 'claims.json' --pipeline-parameters 'detection_endpoint=$detection_endpoint' --parameter-pass-method 'env' "
          - $(inputs.params.detection_endpoint)
          command:
          - sh
          - -c
          env:
          - name: AWS_ACCESS_KEY_ID
            valueFrom:
              secretKeyRef:
                key: AWS_ACCESS_KEY_ID
                name: aws-connection-minio-pipeline
          - name: AWS_SECRET_ACCESS_KEY
            valueFrom:
              secretKeyRef:
                key: AWS_SECRET_ACCESS_KEY
                name: aws-connection-minio-pipeline
          - name: ELYRA_RUNTIME_ENV
            value: kfp
          - name: ELYRA_ENABLE_PIPELINE_INFO
            value: "True"
          - name: ELYRA_WRITABLE_CONTAINER_DIR
            value: /tmp
          - name: ELYRA_RUN_NAME
            valueFrom:
              fieldRef:
                fieldPath: metadata.annotations['pipelines.kubeflow.org/run_name']
          image: quay.io/rh-aiservices-bu/rhoai-lab-insurance-claim-processing-pipeline:1.0
        params:
        - name: detection_endpoint
        stepTemplate:
          volumeMounts:
          - name: mlpipeline-metrics
            mountPath: /tmp
        volumes:
        - name: mlpipeline-metrics
          emptyDir: {}
        metadata:
          labels:
            elyra/node-type: notebook-script
            elyra/pipeline-name: process_claims
            elyra/pipeline-version: ''
            elyra/experiment-name: ''
            elyra/node-name: detect_objects
            pipelines.kubeflow.org/cache_enabled: "true"
          annotations:
            elyra/node-file-name: insurance-claim-processing/lab-materials/05/05-05/detect_objects.py
            elyra/pipeline-source: process_claims.pipeline
            pipelines.kubeflow.org/task_display_name: detect_objects
            pipelines.kubeflow.org/component_spec_digest: '{"name": "Run a file",
              "outputs": [], "version": "Run a file@sha256=2c90640ce8b2534f6165c2861aa0e2cefc2f204d6c414c4d08ab01ec9e62bf7a"}'
      runAfter:
      - run-a-file
    - name: run-a-file-6
      taskSpec:
        steps:
        - name: main
          args:
          - |
            sh -c "mkdir -p ./jupyter-work-dir && cd ./jupyter-work-dir"
            sh -c "echo 'Downloading file:///opt/app-root/bin/utils/bootstrapper.py' && curl --fail -H 'Cache-Control: no-cache' -L file:///opt/app-root/bin/utils/bootstrapper.py --output bootstrapper.py"
            sh -c "echo 'Downloading file:///opt/app-root/bin/utils/requirements-elyra.txt' && curl --fail -H 'Cache-Control: no-cache' -L file:///opt/app-root/bin/utils/requirements-elyra.txt --output requirements-elyra.txt"
            sh -c "python3 -m pip install  packaging && python3 -m pip freeze > requirements-current.txt && python3 bootstrapper.py --pipeline-name 'process_claims' --cos-endpoint 'https://minio-api-robert-serving-test.apps.rhods-internal.61tk.p1.openshiftapps.com' --cos-bucket 'pipeline-bucket' --cos-directory 'process_claims-0111164720' --cos-dependencies-archive 'summarize_text-af47e64c-33fb-4881-b6ee-6ffa382a33e1.tar.gz' --file 'insurance-claim-processing/lab-materials/05/05-05/summarize_text.py' --inputs 'claims.json' "
          command:
          - sh
          - -c
          env:
          - name: AWS_ACCESS_KEY_ID
            valueFrom:
              secretKeyRef:
                key: AWS_ACCESS_KEY_ID
                name: aws-connection-minio-pipeline
          - name: AWS_SECRET_ACCESS_KEY
            valueFrom:
              secretKeyRef:
                key: AWS_SECRET_ACCESS_KEY
                name: aws-connection-minio-pipeline
          - name: ELYRA_RUNTIME_ENV
            value: kfp
          - name: ELYRA_ENABLE_PIPELINE_INFO
            value: "True"
          - name: ELYRA_WRITABLE_CONTAINER_DIR
            value: /tmp
          - name: ELYRA_RUN_NAME
            valueFrom:
              fieldRef:
                fieldPath: metadata.annotations['pipelines.kubeflow.org/run_name']
          image: quay.io/rh-aiservices-bu/rhoai-lab-insurance-claim-processing-pipeline:1.0
        stepTemplate:
          volumeMounts:
          - name: mlpipeline-metrics
            mountPath: /tmp
        volumes:
        - name: mlpipeline-metrics
          emptyDir: {}
        metadata:
          labels:
            elyra/node-type: notebook-script
            elyra/pipeline-name: process_claims
            elyra/pipeline-version: ''
            elyra/experiment-name: ''
            elyra/node-name: summarize_text
            pipelines.kubeflow.org/cache_enabled: "true"
          annotations:
            elyra/node-file-name: insurance-claim-processing/lab-materials/05/05-05/summarize_text.py
            elyra/pipeline-source: process_claims.pipeline
            pipelines.kubeflow.org/task_display_name: summarize_text
            pipelines.kubeflow.org/component_spec_digest: '{"name": "Run a file",
              "outputs": [], "version": "Run a file@sha256=db618b5962e9d8c5507df90e3360408e6694e8efc303936ed675b26eff7b77aa"}'
      runAfter:
      - run-a-file
